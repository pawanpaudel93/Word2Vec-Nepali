{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec_Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvXJjbakDdRu",
        "colab_type": "code",
        "outputId": "dceee42e-6112-4ad4-d8f5-5d5a6b0395d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFPUoOt7Dh4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc0uCFNBDt47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 62549 + 1 # Atleast 3 count needed for word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBz0DLrqFAxX",
        "colab_type": "code",
        "outputId": "8dbb9a00-aa0a-4a0e-8e50-cb328d5f5bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!rsync -P \"/content/gdrive/My Drive/NLP/gdrive.py\" ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive.py\n",
            "\r            964 100%    0.00kB/s    0:00:00  \r            964 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=0/1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1_bSHP2FDSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gdrive import download_file_from_google_drive\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QltLvh3vFIPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download_file_from_google_drive('178Ulc0pKZCFVMKK0P4V3ldZaxpp35Lh0', '/content/tokenizer.pickle')\n",
        "download_file_from_google_drive('1-0V1subnINsCm1rFa36PTkgVmKjp7SeT', '/content/NepWord2VecTrainingData.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojdOb91MDvrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BkvMKBUyqB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras.layers import Input, Dense, Reshape\n",
        "from tensorflow.python.keras.layers import Embedding\n",
        "from tensorflow.python.keras.layers.merge import dot\n",
        "from tensorflow.python.keras.models import Model,load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv1W41XbAfKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.initializers import TruncatedNormal\n",
        "from tensorflow.python.keras.optimizers import Adagrad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LURA6SSzh9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Word2Vec(Layer):\n",
        "  \n",
        "  def __init__(self, embed_dim, vocab_size, **kwargs):\n",
        "    self.embed_dim = embed_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    super(Word2Vec, self).__init__(**kwargs)\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    stddev = 1/np.sqrt(self.embed_dim)\n",
        "    initializer = TruncatedNormal(stddev=stddev)\n",
        "    # word embedding shape (10000,300) for my use\n",
        "    # word embedding input=> (batch_size,sequence_length) output => (batch_size, sequence_length, 300(output_dim))\n",
        "    self.word_embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embed_dim, \n",
        "                     input_length=1, name=\"word_embedding\", embeddings_initializer=initializer)\n",
        "    self.context_embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embed_dim, \n",
        "                     input_length=1, name=\"context_embedding\", embeddings_initializer=initializer)\n",
        "#     self.trainable_weights=[self.word_embedding, self.context_embedding]\n",
        "    super(Word2Vec, self).build(input_shape)\n",
        "  \n",
        "  def call(self, inputs, **kwargs):\n",
        "    target_input, context_input = inputs\n",
        "    target = self.word_embedding(target_input)\n",
        "    context = self.context_embedding(context_input)\n",
        "    # shape target: (batch_size, sequence_length, embed_size) => (batch_size,1,300)\n",
        "    # shape context: (batch_size, sequence_length, embed_size) => (batch_size,1,300)\n",
        "    dot_product = dot([target,context], axes=(2,2))\n",
        "    dot_product = Reshape(target_shape=(1,))(dot_product)\n",
        "    output = Dense(1, activation='sigmoid')(dot_product)\n",
        "    return output\n",
        "  \n",
        "  def get_config(self):\n",
        "    config = super(Word2Vec, self).get_config()\n",
        "    config.update({\n",
        "        'embed_dim': self.embed_dim,\n",
        "        'vocab_size': self.vocab_size\n",
        "    })\n",
        "    return config\n",
        "  \n",
        "custom_layers = {\n",
        "    Word2Vec.__name__: Word2Vec\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pex4wkLX6yyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(embed_dim,vocab_size):\n",
        "  target_input = Input(shape=(1,), name=\"target_input\")\n",
        "  context_input = Input(shape=(1,), name=\"context_input\")\n",
        "  word2vec = Word2Vec(embed_dim=embed_dim, vocab_size=vocab_size)\n",
        "  output = word2vec([target_input, context_input])\n",
        "\n",
        "  model = Model(inputs=[target_input,context_input], outputs=output, name=\"Word2Vec\")\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I0IDPfV-Epp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer=Adagrad() was not supported on loading the saved model => https://stackoverflow.com/questions/47092185/tensorflow-word2vec-model-running-on-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FD7Oql0GAYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.utils import Sequence\n",
        "# from keras.utils import Sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbBm2GM-ekq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainGenerator(Sequence):\n",
        "  \n",
        "  def __init__(self, batch_size):\n",
        "    self.batch_size = batch_size\n",
        "    # get train data from saved file\n",
        "    self.train_data = np.load('NepWord2VecTrainingData.npy')\n",
        "    \n",
        "  def __len__(self):\n",
        "    return int(len(self.train_data) / self.batch_size)\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    train_data = self.train_data\n",
        "    target_inputs = train_data[index*self.batch_size:(index+1)*self.batch_size,0]\n",
        "    context_inputs = train_data[index*self.batch_size:(index+1)*self.batch_size,1]\n",
        "    target_inputs = target_inputs.reshape(self.batch_size,1)\n",
        "    context_inputs = context_inputs.reshape(self.batch_size,1)\n",
        "    output_labels = train_data[index*self.batch_size:(index+1)*self.batch_size,2]\n",
        "    return [target_inputs, context_inputs], output_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znNQo26-6MMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fKXGjj-HM2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob, os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vktp6qKxCmPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = '/content/gdrive/My Drive/NLP/Word2Vec/training_logs/Word2Vec-Nepali'\n",
        "MODEL_CHECKPOINT_NAME = 'model{epoch:03d}.hdf5'\n",
        "MODEL_CHECKPOINT_DIRNAME = LOG_DIR + '/checkpoints/'\n",
        "MODEL_CHECKPOINT_BEST = LOG_DIR + '/best/'\n",
        "log_dir = './logs'  # Tensorboard\n",
        "!mkdir -p '{MODEL_CHECKPOINT_DIRNAME}'\n",
        "!mkdir -p '{MODEL_CHECKPOINT_BEST}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dO_X9z8HJgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('/content/ngrok-stable-linux-amd64.zip'):\n",
        "  !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "  !unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qCbT0VfHY6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(log_dir)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DesJ4J2vHaQu",
        "colab_type": "code",
        "outputId": "7c29f7f5-6ec4-429d-8069-dc1a094ec8dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "get_ipython().system_raw('./ngrok authtoken 4LoCPh77Ein9HNXiHKJXx_48gvTwxa9wfQKrjK84UXp &')\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://973adbc8.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzrHaFasHgpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import re, os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd79uAbBHllV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_init_epoch(check_point_path):\n",
        "    check_point_list = glob.glob(os.path.join(check_point_path, 'model*.hdf5'))\n",
        "    base_names = [os.path.basename(check_point) for check_point in check_point_list]\n",
        "    epochs = [int(re.search(r'\\d+', string).group()) for string in base_names]\n",
        "    return np.max(epochs) if epochs else 0\n",
        "  \n",
        "def load_saved_model(model_path):\n",
        "    return load_model(model_path, custom_objects=custom_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVDtxd9qIMdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_epoch = get_init_epoch(MODEL_CHECKPOINT_DIRNAME)\n",
        "if init_epoch:\n",
        "    model_path = MODEL_CHECKPOINT_DIRNAME + MODEL_CHECKPOINT_NAME.format(epoch=init_epoch)\n",
        "#     model = load_saved_model(model_path)\n",
        "    model = get_model(300,vocab_size)\n",
        "    model.load_weights(model_path)\n",
        "# init_epoch\n",
        "model_path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aeCEwFuPIfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [TensorBoard(log_dir, update_freq='batch'),\n",
        "             ModelCheckpoint(MODEL_CHECKPOINT_DIRNAME + MODEL_CHECKPOINT_NAME)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLouBtZU6vGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = TrainGenerator(512)\n",
        "model.fit_generator(generator=generator, epochs=100, callbacks=callbacks, initial_epoch=init_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}